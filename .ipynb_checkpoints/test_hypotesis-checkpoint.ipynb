{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritm Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will compare the performance of the two algorithms - without relabeling and with relabeling - through their test sample f1 score and the norm of the weights from the hidden layer and the output layers. The null hypothesis for each case is that the new methodolody does not **improve** the performance, and the results are the same. The alternative hypothesis is that the second algorithm **generates an improvement** in the respective metric under test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv files and data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read.csv('result_moons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X</th><th scope=col>f1_score_before</th><th scope=col>f1_score_after</th><th scope=col>norm_1_before</th><th scope=col>norm_1_after</th><th scope=col>norm_2_before</th><th scope=col>norm_2_after</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>0.8971234</td><td>0.9389430</td><td>44.54125</td><td>22.11043</td><td>27.98088</td><td>25.18419</td></tr>\n",
       "\t<tr><td>1</td><td>0.8750000</td><td>0.9137750</td><td>37.09127</td><td>17.21556</td><td>36.53730</td><td>19.96331</td></tr>\n",
       "\t<tr><td>2</td><td>0.9280156</td><td>0.9462151</td><td>41.68607</td><td>15.10151</td><td>35.73296</td><td>15.94568</td></tr>\n",
       "\t<tr><td>3</td><td>0.9126984</td><td>0.9412356</td><td>26.14099</td><td>21.61062</td><td>25.75867</td><td>24.30530</td></tr>\n",
       "\t<tr><td>4</td><td>0.8964435</td><td>0.9469027</td><td>50.95062</td><td>23.04784</td><td>43.35037</td><td>24.08169</td></tr>\n",
       "\t<tr><td>5</td><td>0.8650190</td><td>0.9259826</td><td>46.08482</td><td>15.48541</td><td>44.53597</td><td>17.53767</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       " X & f1\\_score\\_before & f1\\_score\\_after & norm\\_1\\_before & norm\\_1\\_after & norm\\_2\\_before & norm\\_2\\_after\\\\\n",
       " <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 0.8971234 & 0.9389430 & 44.54125 & 22.11043 & 27.98088 & 25.18419\\\\\n",
       "\t 1 & 0.8750000 & 0.9137750 & 37.09127 & 17.21556 & 36.53730 & 19.96331\\\\\n",
       "\t 2 & 0.9280156 & 0.9462151 & 41.68607 & 15.10151 & 35.73296 & 15.94568\\\\\n",
       "\t 3 & 0.9126984 & 0.9412356 & 26.14099 & 21.61062 & 25.75867 & 24.30530\\\\\n",
       "\t 4 & 0.8964435 & 0.9469027 & 50.95062 & 23.04784 & 43.35037 & 24.08169\\\\\n",
       "\t 5 & 0.8650190 & 0.9259826 & 46.08482 & 15.48541 & 44.53597 & 17.53767\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| X &lt;int&gt; | f1_score_before &lt;dbl&gt; | f1_score_after &lt;dbl&gt; | norm_1_before &lt;dbl&gt; | norm_1_after &lt;dbl&gt; | norm_2_before &lt;dbl&gt; | norm_2_after &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 0 | 0.8971234 | 0.9389430 | 44.54125 | 22.11043 | 27.98088 | 25.18419 |\n",
       "| 1 | 0.8750000 | 0.9137750 | 37.09127 | 17.21556 | 36.53730 | 19.96331 |\n",
       "| 2 | 0.9280156 | 0.9462151 | 41.68607 | 15.10151 | 35.73296 | 15.94568 |\n",
       "| 3 | 0.9126984 | 0.9412356 | 26.14099 | 21.61062 | 25.75867 | 24.30530 |\n",
       "| 4 | 0.8964435 | 0.9469027 | 50.95062 | 23.04784 | 43.35037 | 24.08169 |\n",
       "| 5 | 0.8650190 | 0.9259826 | 46.08482 | 15.48541 | 44.53597 | 17.53767 |\n",
       "\n"
      ],
      "text/plain": [
       "  X f1_score_before f1_score_after norm_1_before norm_1_after norm_2_before\n",
       "1 0 0.8971234       0.9389430      44.54125      22.11043     27.98088     \n",
       "2 1 0.8750000       0.9137750      37.09127      17.21556     36.53730     \n",
       "3 2 0.9280156       0.9462151      41.68607      15.10151     35.73296     \n",
       "4 3 0.9126984       0.9412356      26.14099      21.61062     25.75867     \n",
       "5 4 0.8964435       0.9469027      50.95062      23.04784     43.35037     \n",
       "6 5 0.8650190       0.9259826      46.08482      15.48541     44.53597     \n",
       "  norm_2_after\n",
       "1 25.18419    \n",
       "2 19.96331    \n",
       "3 15.94568    \n",
       "4 24.30530    \n",
       "5 24.08169    \n",
       "6 17.53767    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_before <- unlist(data['f1_score_before'], use.names=FALSE)\n",
    "f1_score_after <- unlist(data['f1_score_after'], use.names=FALSE)\n",
    "norm_1_before <- unlist(data['norm_1_before'], use.names=FALSE)\n",
    "norm_1_after <- unlist(data['norm_1_after'], use.names=FALSE)\n",
    "norm_2_before <- unlist(data['norm_2_before'], use.names=FALSE)\n",
    "norm_2_after <- unlist(data['norm_2_after'], use.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  f1_score_before\n",
       "W = 0.98859, p-value = 0.982\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(f1_score_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  f1_score_before\n",
       "W = 0.98859, p-value = 0.982\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(f1_score_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test weights norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_1_before\n",
       "W = 0.97713, p-value = 0.7451\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_1_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_1_after\n",
       "W = 0.97887, p-value = 0.7949\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_1_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_2_before\n",
       "W = 0.9593, p-value = 0.2973\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_2_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_2_after\n",
       "W = 0.97843, p-value = 0.7824\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_2_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, for all metrics considered, the p-value for the Shapiro-Wilk test was higher than 0.05, considering an hypothesis thest with 95% of accuracy. This means that the null hypothesis that the data came from a normal distribution cannot be negated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if the proposed algorithm improved the f1 score of the sample data, a t test can be performed, considering the normality of the samples. We are intereste in find deviations from value greater 2% to consider an improvement. So the effect size of the test, $\\delta^*$ is calculated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\delta^* = 0.02 * E[\\text{f1_score_before}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0180997958980772"
      ],
      "text/latex": [
       "0.0180997958980772"
      ],
      "text/markdown": [
       "0.0180997958980772"
      ],
      "text/plain": [
       "[1] 0.0180998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0.02*mean(f1_score_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of the test, then, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     Two-sample t test power calculation \n",
       "\n",
       "              n = 30\n",
       "          delta = 0.0180998\n",
       "             sd = 0.02355011\n",
       "      sig.level = 0.05\n",
       "          power = 0.9026465\n",
       "    alternative = one.sided\n",
       "\n",
       "NOTE: n is number in *each* group\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "power.t.test(sig.level = 0.05, \n",
    "             n=30, \n",
    "             sd = sd(f1_score_before), \n",
    "             delta=0.02*mean(f1_score_before), \n",
    "             type='two.sample', \n",
    "             alternative='one.sided'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying t test for the f1 score samples, from before adjustment and after adjustment, the result is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  f1_score_before and f1_score_after\n",
       "t = -6.3554, df = 51.308, p-value = 2.77e-08\n",
       "alternative hypothesis: true difference in means is less than 0\n",
       "95 percent confidence interval:\n",
       "        -Inf -0.02439342\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "0.9049898 0.9381137 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(f1_score_before, f1_score_after, alternative='less', conf=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the test allow us to negate the null hypothesis of same performance, so the second algorithm is better than the first one considering the f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the norm of the weight from the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the norm, we have 30 samples, from the runs performed, and want a power of 0.8 at least. Considering these parameters, the effective size obtained, which will be the lowest difference value considered to do the comparisons is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta value =  12.62151 %"
     ]
    }
   ],
   "source": [
    "delta <- power.t.test(sig.level = 0.05, \n",
    "             n=30, \n",
    "             sd = sd(norm_1_before), \n",
    "             power=0.8, \n",
    "             type='two.sample', \n",
    "             alternative='one.sided'\n",
    "            )$delta\n",
    "\n",
    "cat(\"Delta value = \", delta / mean(norm_1_before) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  norm_1_before and norm_1_after\n",
       "t = 10.148, df = 50.366, p-value = 4.494e-14\n",
       "alternative hypothesis: true difference in means is greater than 0\n",
       "95 percent confidence interval:\n",
       " 13.99586      Inf\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 38.81299  22.04913 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(norm_1_before, norm_1_after, alternative='greater', conf=0.95, var.equal = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value allow us to negate the null  hypothesis of same norm for each algorithm, and indicates the possibility that the second one is better then the first one with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the norm of the weighs from the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta value =  13.9734 %"
     ]
    }
   ],
   "source": [
    "delta <- power.t.test(sig.level = 0.05, \n",
    "             n=30, \n",
    "             sd = sd(norm_2_before), \n",
    "             power=0.8, \n",
    "             type='two.sample', \n",
    "             alternative='one.sided'\n",
    "            )$delta\n",
    "\n",
    "cat(\"Delta value = \", delta / mean(norm_2_before) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  norm_2_before and norm_2_after\n",
       "t = 5.8182, df = 52.757, p-value = 1.784e-07\n",
       "alternative hypothesis: true difference in means is greater than 0\n",
       "95 percent confidence interval:\n",
       " 6.706916      Inf\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 33.42141  24.00473 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(norm_2_before, norm_2_after, alternative='greater', conf=0.95, var.equal = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as obtained for the weights of the hidden layer, the p-value allow us to infer that the second algorithm is better than the first one with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed algorithm **improves** the general performance of the MLP, according to an improvement of the f1 score. It helps to reduce the model complexity through a reduce on weights norms from all layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
