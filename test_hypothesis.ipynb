{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritm Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will compare the performance of the two algorithms - without relabeling and with relabeling - through their test sample f1 score and the norm of the weights from the hidden layer and the output layers. The null hypothesis for each case is that the new methodolody does not **improve** the performance, and the results are the same. The alternative hypothesis is that the second algorithm **generates an improvement** in the respective metric under test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv files and data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read.csv('result_moons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 30 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X</th><th scope=col>f1_score_before</th><th scope=col>f1_score_after</th><th scope=col>norm_1_before</th><th scope=col>norm_1_after</th><th scope=col>norm_2_before</th><th scope=col>norm_2_after</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0</td><td>0.8971234</td><td>0.9389430</td><td>44.54125</td><td>22.11043</td><td>27.98088</td><td>25.18419</td></tr>\n",
       "\t<tr><td> 1</td><td>0.8750000</td><td>0.9137750</td><td>37.09127</td><td>17.21556</td><td>36.53730</td><td>19.96331</td></tr>\n",
       "\t<tr><td> 2</td><td>0.9280156</td><td>0.9462151</td><td>41.68607</td><td>15.10151</td><td>35.73296</td><td>15.94568</td></tr>\n",
       "\t<tr><td> 3</td><td>0.9126984</td><td>0.9412356</td><td>26.14099</td><td>21.61062</td><td>25.75867</td><td>24.30530</td></tr>\n",
       "\t<tr><td> 4</td><td>0.8964435</td><td>0.9469027</td><td>50.95062</td><td>23.04784</td><td>43.35037</td><td>24.08169</td></tr>\n",
       "\t<tr><td> 5</td><td>0.8650190</td><td>0.9259826</td><td>46.08482</td><td>15.48541</td><td>44.53597</td><td>17.53767</td></tr>\n",
       "\t<tr><td> 6</td><td>0.9100101</td><td>0.9579832</td><td>39.75700</td><td>26.62559</td><td>38.64276</td><td>29.81303</td></tr>\n",
       "\t<tr><td> 7</td><td>0.9081836</td><td>0.9346939</td><td>41.63853</td><td>28.85500</td><td>39.10304</td><td>32.38657</td></tr>\n",
       "\t<tr><td> 8</td><td>0.9185043</td><td>0.9563059</td><td>30.70163</td><td>18.19153</td><td>27.95891</td><td>20.43901</td></tr>\n",
       "\t<tr><td> 9</td><td>0.8975791</td><td>0.9272541</td><td>40.92339</td><td>21.73500</td><td>35.82499</td><td>23.21619</td></tr>\n",
       "\t<tr><td>10</td><td>0.9131679</td><td>0.9532428</td><td>39.21824</td><td>19.48517</td><td>34.06910</td><td>22.45460</td></tr>\n",
       "\t<tr><td>11</td><td>0.9188927</td><td>0.9349845</td><td>35.14452</td><td>22.25181</td><td>32.34488</td><td>24.69767</td></tr>\n",
       "\t<tr><td>12</td><td>0.8922495</td><td>0.9203903</td><td>32.77432</td><td>16.71944</td><td>27.28613</td><td>16.88169</td></tr>\n",
       "\t<tr><td>13</td><td>0.9409348</td><td>0.9438878</td><td>32.18093</td><td>14.77552</td><td>26.53548</td><td>15.14056</td></tr>\n",
       "\t<tr><td>14</td><td>0.9297796</td><td>0.9703369</td><td>38.81369</td><td>27.14443</td><td>32.57490</td><td>25.74353</td></tr>\n",
       "\t<tr><td>15</td><td>0.8915046</td><td>0.9291646</td><td>39.69595</td><td>18.39692</td><td>40.58002</td><td>20.38885</td></tr>\n",
       "\t<tr><td>16</td><td>0.9360076</td><td>0.9323155</td><td>31.57351</td><td>26.92752</td><td>22.66277</td><td>28.15214</td></tr>\n",
       "\t<tr><td>17</td><td>0.8577610</td><td>0.9329870</td><td>46.23108</td><td>18.99441</td><td>44.33314</td><td>22.60922</td></tr>\n",
       "\t<tr><td>18</td><td>0.9397233</td><td>0.9438091</td><td>22.88055</td><td>22.03920</td><td>17.49652</td><td>22.47155</td></tr>\n",
       "\t<tr><td>19</td><td>0.8813071</td><td>0.9553571</td><td>47.30286</td><td>21.43287</td><td>41.69669</td><td>24.88563</td></tr>\n",
       "\t<tr><td>20</td><td>0.8819227</td><td>0.9155878</td><td>51.40882</td><td>27.84897</td><td>37.35281</td><td>31.28050</td></tr>\n",
       "\t<tr><td>21</td><td>0.9537367</td><td>0.9455782</td><td>31.65093</td><td>12.93688</td><td>25.63890</td><td>15.11806</td></tr>\n",
       "\t<tr><td>22</td><td>0.9027356</td><td>0.9336078</td><td>38.67894</td><td>26.49083</td><td>36.00693</td><td>27.59083</td></tr>\n",
       "\t<tr><td>23</td><td>0.9062049</td><td>0.9376238</td><td>53.10080</td><td>17.12207</td><td>42.06750</td><td>19.70805</td></tr>\n",
       "\t<tr><td>24</td><td>0.9239823</td><td>0.9588089</td><td>38.43502</td><td>23.86466</td><td>29.59827</td><td>28.93876</td></tr>\n",
       "\t<tr><td>25</td><td>0.9127996</td><td>0.9079940</td><td>31.05733</td><td>23.87658</td><td>25.78217</td><td>24.22511</td></tr>\n",
       "\t<tr><td>26</td><td>0.9029228</td><td>0.9439348</td><td>38.02516</td><td>25.60834</td><td>32.72431</td><td>25.29688</td></tr>\n",
       "\t<tr><td>27</td><td>0.8660000</td><td>0.8993147</td><td>30.63306</td><td>33.87146</td><td>26.59734</td><td>35.66641</td></tr>\n",
       "\t<tr><td>28</td><td>0.8898899</td><td>0.9534413</td><td>48.48291</td><td>22.91649</td><td>42.73379</td><td>25.72920</td></tr>\n",
       "\t<tr><td>29</td><td>0.8995943</td><td>0.9417523</td><td>37.58564</td><td>28.79195</td><td>29.13486</td><td>30.28997</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 30 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       " X & f1\\_score\\_before & f1\\_score\\_after & norm\\_1\\_before & norm\\_1\\_after & norm\\_2\\_before & norm\\_2\\_after\\\\\n",
       " <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  0 & 0.8971234 & 0.9389430 & 44.54125 & 22.11043 & 27.98088 & 25.18419\\\\\n",
       "\t  1 & 0.8750000 & 0.9137750 & 37.09127 & 17.21556 & 36.53730 & 19.96331\\\\\n",
       "\t  2 & 0.9280156 & 0.9462151 & 41.68607 & 15.10151 & 35.73296 & 15.94568\\\\\n",
       "\t  3 & 0.9126984 & 0.9412356 & 26.14099 & 21.61062 & 25.75867 & 24.30530\\\\\n",
       "\t  4 & 0.8964435 & 0.9469027 & 50.95062 & 23.04784 & 43.35037 & 24.08169\\\\\n",
       "\t  5 & 0.8650190 & 0.9259826 & 46.08482 & 15.48541 & 44.53597 & 17.53767\\\\\n",
       "\t  6 & 0.9100101 & 0.9579832 & 39.75700 & 26.62559 & 38.64276 & 29.81303\\\\\n",
       "\t  7 & 0.9081836 & 0.9346939 & 41.63853 & 28.85500 & 39.10304 & 32.38657\\\\\n",
       "\t  8 & 0.9185043 & 0.9563059 & 30.70163 & 18.19153 & 27.95891 & 20.43901\\\\\n",
       "\t  9 & 0.8975791 & 0.9272541 & 40.92339 & 21.73500 & 35.82499 & 23.21619\\\\\n",
       "\t 10 & 0.9131679 & 0.9532428 & 39.21824 & 19.48517 & 34.06910 & 22.45460\\\\\n",
       "\t 11 & 0.9188927 & 0.9349845 & 35.14452 & 22.25181 & 32.34488 & 24.69767\\\\\n",
       "\t 12 & 0.8922495 & 0.9203903 & 32.77432 & 16.71944 & 27.28613 & 16.88169\\\\\n",
       "\t 13 & 0.9409348 & 0.9438878 & 32.18093 & 14.77552 & 26.53548 & 15.14056\\\\\n",
       "\t 14 & 0.9297796 & 0.9703369 & 38.81369 & 27.14443 & 32.57490 & 25.74353\\\\\n",
       "\t 15 & 0.8915046 & 0.9291646 & 39.69595 & 18.39692 & 40.58002 & 20.38885\\\\\n",
       "\t 16 & 0.9360076 & 0.9323155 & 31.57351 & 26.92752 & 22.66277 & 28.15214\\\\\n",
       "\t 17 & 0.8577610 & 0.9329870 & 46.23108 & 18.99441 & 44.33314 & 22.60922\\\\\n",
       "\t 18 & 0.9397233 & 0.9438091 & 22.88055 & 22.03920 & 17.49652 & 22.47155\\\\\n",
       "\t 19 & 0.8813071 & 0.9553571 & 47.30286 & 21.43287 & 41.69669 & 24.88563\\\\\n",
       "\t 20 & 0.8819227 & 0.9155878 & 51.40882 & 27.84897 & 37.35281 & 31.28050\\\\\n",
       "\t 21 & 0.9537367 & 0.9455782 & 31.65093 & 12.93688 & 25.63890 & 15.11806\\\\\n",
       "\t 22 & 0.9027356 & 0.9336078 & 38.67894 & 26.49083 & 36.00693 & 27.59083\\\\\n",
       "\t 23 & 0.9062049 & 0.9376238 & 53.10080 & 17.12207 & 42.06750 & 19.70805\\\\\n",
       "\t 24 & 0.9239823 & 0.9588089 & 38.43502 & 23.86466 & 29.59827 & 28.93876\\\\\n",
       "\t 25 & 0.9127996 & 0.9079940 & 31.05733 & 23.87658 & 25.78217 & 24.22511\\\\\n",
       "\t 26 & 0.9029228 & 0.9439348 & 38.02516 & 25.60834 & 32.72431 & 25.29688\\\\\n",
       "\t 27 & 0.8660000 & 0.8993147 & 30.63306 & 33.87146 & 26.59734 & 35.66641\\\\\n",
       "\t 28 & 0.8898899 & 0.9534413 & 48.48291 & 22.91649 & 42.73379 & 25.72920\\\\\n",
       "\t 29 & 0.8995943 & 0.9417523 & 37.58564 & 28.79195 & 29.13486 & 30.28997\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 30 × 7\n",
       "\n",
       "| X &lt;int&gt; | f1_score_before &lt;dbl&gt; | f1_score_after &lt;dbl&gt; | norm_1_before &lt;dbl&gt; | norm_1_after &lt;dbl&gt; | norm_2_before &lt;dbl&gt; | norm_2_after &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  0 | 0.8971234 | 0.9389430 | 44.54125 | 22.11043 | 27.98088 | 25.18419 |\n",
       "|  1 | 0.8750000 | 0.9137750 | 37.09127 | 17.21556 | 36.53730 | 19.96331 |\n",
       "|  2 | 0.9280156 | 0.9462151 | 41.68607 | 15.10151 | 35.73296 | 15.94568 |\n",
       "|  3 | 0.9126984 | 0.9412356 | 26.14099 | 21.61062 | 25.75867 | 24.30530 |\n",
       "|  4 | 0.8964435 | 0.9469027 | 50.95062 | 23.04784 | 43.35037 | 24.08169 |\n",
       "|  5 | 0.8650190 | 0.9259826 | 46.08482 | 15.48541 | 44.53597 | 17.53767 |\n",
       "|  6 | 0.9100101 | 0.9579832 | 39.75700 | 26.62559 | 38.64276 | 29.81303 |\n",
       "|  7 | 0.9081836 | 0.9346939 | 41.63853 | 28.85500 | 39.10304 | 32.38657 |\n",
       "|  8 | 0.9185043 | 0.9563059 | 30.70163 | 18.19153 | 27.95891 | 20.43901 |\n",
       "|  9 | 0.8975791 | 0.9272541 | 40.92339 | 21.73500 | 35.82499 | 23.21619 |\n",
       "| 10 | 0.9131679 | 0.9532428 | 39.21824 | 19.48517 | 34.06910 | 22.45460 |\n",
       "| 11 | 0.9188927 | 0.9349845 | 35.14452 | 22.25181 | 32.34488 | 24.69767 |\n",
       "| 12 | 0.8922495 | 0.9203903 | 32.77432 | 16.71944 | 27.28613 | 16.88169 |\n",
       "| 13 | 0.9409348 | 0.9438878 | 32.18093 | 14.77552 | 26.53548 | 15.14056 |\n",
       "| 14 | 0.9297796 | 0.9703369 | 38.81369 | 27.14443 | 32.57490 | 25.74353 |\n",
       "| 15 | 0.8915046 | 0.9291646 | 39.69595 | 18.39692 | 40.58002 | 20.38885 |\n",
       "| 16 | 0.9360076 | 0.9323155 | 31.57351 | 26.92752 | 22.66277 | 28.15214 |\n",
       "| 17 | 0.8577610 | 0.9329870 | 46.23108 | 18.99441 | 44.33314 | 22.60922 |\n",
       "| 18 | 0.9397233 | 0.9438091 | 22.88055 | 22.03920 | 17.49652 | 22.47155 |\n",
       "| 19 | 0.8813071 | 0.9553571 | 47.30286 | 21.43287 | 41.69669 | 24.88563 |\n",
       "| 20 | 0.8819227 | 0.9155878 | 51.40882 | 27.84897 | 37.35281 | 31.28050 |\n",
       "| 21 | 0.9537367 | 0.9455782 | 31.65093 | 12.93688 | 25.63890 | 15.11806 |\n",
       "| 22 | 0.9027356 | 0.9336078 | 38.67894 | 26.49083 | 36.00693 | 27.59083 |\n",
       "| 23 | 0.9062049 | 0.9376238 | 53.10080 | 17.12207 | 42.06750 | 19.70805 |\n",
       "| 24 | 0.9239823 | 0.9588089 | 38.43502 | 23.86466 | 29.59827 | 28.93876 |\n",
       "| 25 | 0.9127996 | 0.9079940 | 31.05733 | 23.87658 | 25.78217 | 24.22511 |\n",
       "| 26 | 0.9029228 | 0.9439348 | 38.02516 | 25.60834 | 32.72431 | 25.29688 |\n",
       "| 27 | 0.8660000 | 0.8993147 | 30.63306 | 33.87146 | 26.59734 | 35.66641 |\n",
       "| 28 | 0.8898899 | 0.9534413 | 48.48291 | 22.91649 | 42.73379 | 25.72920 |\n",
       "| 29 | 0.8995943 | 0.9417523 | 37.58564 | 28.79195 | 29.13486 | 30.28997 |\n",
       "\n"
      ],
      "text/plain": [
       "   X  f1_score_before f1_score_after norm_1_before norm_1_after norm_2_before\n",
       "1   0 0.8971234       0.9389430      44.54125      22.11043     27.98088     \n",
       "2   1 0.8750000       0.9137750      37.09127      17.21556     36.53730     \n",
       "3   2 0.9280156       0.9462151      41.68607      15.10151     35.73296     \n",
       "4   3 0.9126984       0.9412356      26.14099      21.61062     25.75867     \n",
       "5   4 0.8964435       0.9469027      50.95062      23.04784     43.35037     \n",
       "6   5 0.8650190       0.9259826      46.08482      15.48541     44.53597     \n",
       "7   6 0.9100101       0.9579832      39.75700      26.62559     38.64276     \n",
       "8   7 0.9081836       0.9346939      41.63853      28.85500     39.10304     \n",
       "9   8 0.9185043       0.9563059      30.70163      18.19153     27.95891     \n",
       "10  9 0.8975791       0.9272541      40.92339      21.73500     35.82499     \n",
       "11 10 0.9131679       0.9532428      39.21824      19.48517     34.06910     \n",
       "12 11 0.9188927       0.9349845      35.14452      22.25181     32.34488     \n",
       "13 12 0.8922495       0.9203903      32.77432      16.71944     27.28613     \n",
       "14 13 0.9409348       0.9438878      32.18093      14.77552     26.53548     \n",
       "15 14 0.9297796       0.9703369      38.81369      27.14443     32.57490     \n",
       "16 15 0.8915046       0.9291646      39.69595      18.39692     40.58002     \n",
       "17 16 0.9360076       0.9323155      31.57351      26.92752     22.66277     \n",
       "18 17 0.8577610       0.9329870      46.23108      18.99441     44.33314     \n",
       "19 18 0.9397233       0.9438091      22.88055      22.03920     17.49652     \n",
       "20 19 0.8813071       0.9553571      47.30286      21.43287     41.69669     \n",
       "21 20 0.8819227       0.9155878      51.40882      27.84897     37.35281     \n",
       "22 21 0.9537367       0.9455782      31.65093      12.93688     25.63890     \n",
       "23 22 0.9027356       0.9336078      38.67894      26.49083     36.00693     \n",
       "24 23 0.9062049       0.9376238      53.10080      17.12207     42.06750     \n",
       "25 24 0.9239823       0.9588089      38.43502      23.86466     29.59827     \n",
       "26 25 0.9127996       0.9079940      31.05733      23.87658     25.78217     \n",
       "27 26 0.9029228       0.9439348      38.02516      25.60834     32.72431     \n",
       "28 27 0.8660000       0.8993147      30.63306      33.87146     26.59734     \n",
       "29 28 0.8898899       0.9534413      48.48291      22.91649     42.73379     \n",
       "30 29 0.8995943       0.9417523      37.58564      28.79195     29.13486     \n",
       "   norm_2_after\n",
       "1  25.18419    \n",
       "2  19.96331    \n",
       "3  15.94568    \n",
       "4  24.30530    \n",
       "5  24.08169    \n",
       "6  17.53767    \n",
       "7  29.81303    \n",
       "8  32.38657    \n",
       "9  20.43901    \n",
       "10 23.21619    \n",
       "11 22.45460    \n",
       "12 24.69767    \n",
       "13 16.88169    \n",
       "14 15.14056    \n",
       "15 25.74353    \n",
       "16 20.38885    \n",
       "17 28.15214    \n",
       "18 22.60922    \n",
       "19 22.47155    \n",
       "20 24.88563    \n",
       "21 31.28050    \n",
       "22 15.11806    \n",
       "23 27.59083    \n",
       "24 19.70805    \n",
       "25 28.93876    \n",
       "26 24.22511    \n",
       "27 25.29688    \n",
       "28 35.66641    \n",
       "29 25.72920    \n",
       "30 30.28997    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_before <- unlist(data['f1_score_before'], use.names=FALSE)\n",
    "f1_score_after <- unlist(data['f1_score_after'], use.names=FALSE)\n",
    "norm_1_before <- unlist(data['norm_1_before'], use.names=FALSE)\n",
    "norm_1_after <- unlist(data['norm_1_after'], use.names=FALSE)\n",
    "norm_2_before <- unlist(data['norm_2_before'], use.names=FALSE)\n",
    "norm_2_after <- unlist(data['norm_2_after'], use.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  f1_score_before\n",
       "W = 0.98859, p-value = 0.982\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(f1_score_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  f1_score_before\n",
       "W = 0.98859, p-value = 0.982\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(f1_score_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test weights norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_1_before\n",
       "W = 0.97713, p-value = 0.7451\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_1_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_1_after\n",
       "W = 0.97887, p-value = 0.7949\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_1_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_2_before\n",
       "W = 0.9593, p-value = 0.2973\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_2_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tShapiro-Wilk normality test\n",
       "\n",
       "data:  norm_2_after\n",
       "W = 0.97843, p-value = 0.7824\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapiro.test(norm_2_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, for all metrics considered, the p-value for the Shapiro-Wilk test was higher than 0.05, considering an hypothesis thest with 95% of accuracy. This means that the null hypothesis that the data came from a normal distribution cannot be negated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if the proposed algorithm improved the f1 score of the sample data, a t test can be performed, considering the normality of the samples. We are intereste in find deviations from value greater 2% to consider an improvement. So the effect size of the test, $\\delta^*$ is calculated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\delta^* = 0.02 * E[\\text{f1_score_before}]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0180997958980772"
      ],
      "text/latex": [
       "0.0180997958980772"
      ],
      "text/markdown": [
       "0.0180997958980772"
      ],
      "text/plain": [
       "[1] 0.0180998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0.02*mean(f1_score_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of the test, then, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     Two-sample t test power calculation \n",
       "\n",
       "              n = 30\n",
       "          delta = 0.0180998\n",
       "             sd = 0.02355011\n",
       "      sig.level = 0.05\n",
       "          power = 0.9026465\n",
       "    alternative = one.sided\n",
       "\n",
       "NOTE: n is number in *each* group\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "power.t.test(sig.level = 0.05, \n",
    "             n=30, \n",
    "             sd = sd(f1_score_before), \n",
    "             delta=0.02*mean(f1_score_before), \n",
    "             type='two.sample', \n",
    "             alternative='one.sided'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying t test for the f1 score samples, from before adjustment and after adjustment, the result is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  f1_score_before and f1_score_after\n",
       "t = -6.3554, df = 51.308, p-value = 2.77e-08\n",
       "alternative hypothesis: true difference in means is less than 0\n",
       "95 percent confidence interval:\n",
       "        -Inf -0.02439342\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "0.9049898 0.9381137 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(f1_score_before, f1_score_after, alternative='less', conf=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the test allow us to negate the null hypothesis of same performance, so the second algorithm is better than the first one considering the f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the norm of the weight from the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the norm, we have 30 samples, from the runs performed, and want a power of 0.8 at least. Considering these parameters, the effective size obtained, which will be the lowest difference value considered to do the comparisons is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta value =  12.62151 %"
     ]
    }
   ],
   "source": [
    "delta <- power.t.test(sig.level = 0.05, \n",
    "             n=30, \n",
    "             sd = sd(norm_1_before), \n",
    "             power=0.8, \n",
    "             type='two.sample', \n",
    "             alternative='one.sided'\n",
    "            )$delta\n",
    "\n",
    "cat(\"Delta value = \", delta / mean(norm_1_before) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  norm_1_before and norm_1_after\n",
       "t = 10.148, df = 50.366, p-value = 4.494e-14\n",
       "alternative hypothesis: true difference in means is greater than 0\n",
       "95 percent confidence interval:\n",
       " 13.99586      Inf\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 38.81299  22.04913 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(norm_1_before, norm_1_after, alternative='greater', conf=0.95, var.equal = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value allow us to negate the null  hypothesis of same norm for each algorithm, and indicates the possibility that the second one is better then the first one with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the norm of the weighs from the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta value =  13.9734 %"
     ]
    }
   ],
   "source": [
    "delta <- power.t.test(sig.level = 0.05, \n",
    "             n=30, \n",
    "             sd = sd(norm_2_before), \n",
    "             power=0.8, \n",
    "             type='two.sample', \n",
    "             alternative='one.sided'\n",
    "            )$delta\n",
    "\n",
    "cat(\"Delta value = \", delta / mean(norm_2_before) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  norm_2_before and norm_2_after\n",
       "t = 5.8182, df = 52.757, p-value = 1.784e-07\n",
       "alternative hypothesis: true difference in means is greater than 0\n",
       "95 percent confidence interval:\n",
       " 6.706916      Inf\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 33.42141  24.00473 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(norm_2_before, norm_2_after, alternative='greater', conf=0.95, var.equal = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as obtained for the weights of the hidden layer, the p-value allow us to infer that the second algorithm is better than the first one with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed algorithm **improves** the general performance of the MLP, according to an improvement of the f1 score. It helps to reduce the model complexity through a reduce on weights norms from all layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
